{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\jaysu\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\jaysu\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "# Import dependencies and libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "# Use nltk for tokenizer and stopwords removal\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0       dates                                    tokenized_title  \\\n",
       "0           0         NaN  ['Russo', 'Cam', 'A', 'watery', 'look', 'North...   \n",
       "1           1  2020-11-02  ['Watch', 'Meet', 'Kehu', 'Butler', '20', 'Yea...   \n",
       "2           2  2020-10-17  ['With', 'No', '2020', 'Olympics', 'How', 'Sur...   \n",
       "3           3  2020-10-13  ['Watch', 'Tom', 'Carroll', 'Matt', 'Grainger'...   \n",
       "4           4  2021-01-18  ['A', 'Powerful', 'South', 'SSE', 'Groundswell...   \n",
       "\n",
       "                                      tokenized_copy  \\\n",
       "0  ['On', 'clear', 'winter', 'day', 'balmy', 'coa...   \n",
       "1  ['If', 'know', 'Kehu', 'Butler', 'yet', 'bette...   \n",
       "2  ['Two', 'historic', 'things', 'Surfing', 'inau...   \n",
       "3  ['We', 'got', 'kinds', 'reef', 'around', 'play...   \n",
       "4  ['The', 'month', 'January', 'exactly', 'renown...   \n",
       "\n",
       "                                           tags_text  \\\n",
       "0         [\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]   \n",
       "1                                                 []   \n",
       "2  [\"ISA\",\"Jordy Smith\",\"Olympics\",\"sally fitzgib...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                       string_titles  \\\n",
       "0  Russo Cam A watery look North Shore secret soc...   \n",
       "1  Watch Meet Kehu Butler 20 Year Old Rising Surf...   \n",
       "2         With No 2020 Olympics How Surfers Feeling    \n",
       "3  Watch Tom Carroll Matt Grainger Break Down Tow...   \n",
       "4  A Powerful South SSE Groundswell Is About To R...   \n",
       "\n",
       "                                         string_copy  \\\n",
       "0  On clear winter day balmy coastline Oahu North...   \n",
       "1  If know Kehu Butler yet better way get acquain...   \n",
       "2  Two historic things Surfing inaugural debut Ol...   \n",
       "3  We got kinds reef around play When two time Wo...   \n",
       "4  The month January exactly renowned big south s...   \n",
       "\n",
       "                                  string_tags  word_count  \\\n",
       "0            CBD Daniel Russo InnerG pipeline         197   \n",
       "1                                         NaN         105   \n",
       "2  ISA Jordy Smith Olympics sally fitzgibbons         280   \n",
       "3                                         NaN         148   \n",
       "4                                         NaN         514   \n",
       "\n",
       "                                      wordcount_list  \n",
       "0  {'clear': 1, 'winter': 1, 'day': 1, 'balmy': 1...  \n",
       "1  {'know': 1, 'kehu': 1, 'butler': 1, 'yet': 1, ...  \n",
       "2  {'historic': 1, 'things': 1, 'surfing': 7, 'in...  \n",
       "3  {'got': 1, 'kinds': 1, 'reef': 1, 'around': 2,...  \n",
       "4  {'month': 2, 'january': 2, 'exactly': 1, 'reno...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>dates</th>\n      <th>tokenized_title</th>\n      <th>tokenized_copy</th>\n      <th>tags_text</th>\n      <th>string_titles</th>\n      <th>string_copy</th>\n      <th>string_tags</th>\n      <th>word_count</th>\n      <th>wordcount_list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>['Russo', 'Cam', 'A', 'watery', 'look', 'North...</td>\n      <td>['On', 'clear', 'winter', 'day', 'balmy', 'coa...</td>\n      <td>[\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]</td>\n      <td>Russo Cam A watery look North Shore secret soc...</td>\n      <td>On clear winter day balmy coastline Oahu North...</td>\n      <td>CBD Daniel Russo InnerG pipeline</td>\n      <td>197</td>\n      <td>{'clear': 1, 'winter': 1, 'day': 1, 'balmy': 1...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2020-11-02</td>\n      <td>['Watch', 'Meet', 'Kehu', 'Butler', '20', 'Yea...</td>\n      <td>['If', 'know', 'Kehu', 'Butler', 'yet', 'bette...</td>\n      <td>[]</td>\n      <td>Watch Meet Kehu Butler 20 Year Old Rising Surf...</td>\n      <td>If know Kehu Butler yet better way get acquain...</td>\n      <td>NaN</td>\n      <td>105</td>\n      <td>{'know': 1, 'kehu': 1, 'butler': 1, 'yet': 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2020-10-17</td>\n      <td>['With', 'No', '2020', 'Olympics', 'How', 'Sur...</td>\n      <td>['Two', 'historic', 'things', 'Surfing', 'inau...</td>\n      <td>[\"ISA\",\"Jordy Smith\",\"Olympics\",\"sally fitzgib...</td>\n      <td>With No 2020 Olympics How Surfers Feeling</td>\n      <td>Two historic things Surfing inaugural debut Ol...</td>\n      <td>ISA Jordy Smith Olympics sally fitzgibbons</td>\n      <td>280</td>\n      <td>{'historic': 1, 'things': 1, 'surfing': 7, 'in...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2020-10-13</td>\n      <td>['Watch', 'Tom', 'Carroll', 'Matt', 'Grainger'...</td>\n      <td>['We', 'got', 'kinds', 'reef', 'around', 'play...</td>\n      <td>[]</td>\n      <td>Watch Tom Carroll Matt Grainger Break Down Tow...</td>\n      <td>We got kinds reef around play When two time Wo...</td>\n      <td>NaN</td>\n      <td>148</td>\n      <td>{'got': 1, 'kinds': 1, 'reef': 1, 'around': 2,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2021-01-18</td>\n      <td>['A', 'Powerful', 'South', 'SSE', 'Groundswell...</td>\n      <td>['The', 'month', 'January', 'exactly', 'renown...</td>\n      <td>[]</td>\n      <td>A Powerful South SSE Groundswell Is About To R...</td>\n      <td>The month January exactly renowned big south s...</td>\n      <td>NaN</td>\n      <td>514</td>\n      <td>{'month': 2, 'january': 2, 'exactly': 1, 'reno...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('data/word_count.csv')\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## Word Sentiment Ratings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  happs  rank  stdDev            word\n",
       "0           0    5.1  6648    0.99       according\n",
       "1           1    5.1  6649    1.58  administrative\n",
       "2           2    5.1  6650    1.25          albert\n",
       "3           3    5.1  6651    1.31          alleen\n",
       "4           4    5.1  6652    1.30           allen"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>happs</th>\n      <th>rank</th>\n      <th>stdDev</th>\n      <th>word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>5.1</td>\n      <td>6648</td>\n      <td>0.99</td>\n      <td>according</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>5.1</td>\n      <td>6649</td>\n      <td>1.58</td>\n      <td>administrative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5.1</td>\n      <td>6650</td>\n      <td>1.25</td>\n      <td>albert</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>5.1</td>\n      <td>6651</td>\n      <td>1.31</td>\n      <td>alleen</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>5.1</td>\n      <td>6652</td>\n      <td>1.30</td>\n      <td>allen</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "hedo_df = pd.read_csv('data/word_sentiment_rating.csv')\n",
    "hedo_df.head()"
   ]
  },
  {
   "source": [
    "## Tokenize Words And Remove Stopwords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize each tweet, remove stopwords, and append into a list to be added to dataframe later\n",
    "tokens = []\n",
    "# Cache the stopword function to speed up runtime. Otherwise the loop will access the method each iteration and slow down for loop. \n",
    "cachedStopWords = stopwords.words('english')\n",
    "for tweet in df['string_copy']:\n",
    "    text_tokens = word_tokenize(tweet)\n",
    "    token = [word for word in text_tokens if not word in cachedStopWords]\n",
    "    tokens.append(token)\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0       dates                                    tokenized_title  \\\n",
       "0           0         NaN  ['Russo', 'Cam', 'A', 'watery', 'look', 'North...   \n",
       "1           1  2020-11-02  ['Watch', 'Meet', 'Kehu', 'Butler', '20', 'Yea...   \n",
       "2           2  2020-10-17  ['With', 'No', '2020', 'Olympics', 'How', 'Sur...   \n",
       "3           3  2020-10-13  ['Watch', 'Tom', 'Carroll', 'Matt', 'Grainger'...   \n",
       "4           4  2021-01-18  ['A', 'Powerful', 'South', 'SSE', 'Groundswell...   \n",
       "\n",
       "                                      tokenized_copy  \\\n",
       "0  ['On', 'clear', 'winter', 'day', 'balmy', 'coa...   \n",
       "1  ['If', 'know', 'Kehu', 'Butler', 'yet', 'bette...   \n",
       "2  ['Two', 'historic', 'things', 'Surfing', 'inau...   \n",
       "3  ['We', 'got', 'kinds', 'reef', 'around', 'play...   \n",
       "4  ['The', 'month', 'January', 'exactly', 'renown...   \n",
       "\n",
       "                                           tags_text  \\\n",
       "0         [\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]   \n",
       "1                                                 []   \n",
       "2  [\"ISA\",\"Jordy Smith\",\"Olympics\",\"sally fitzgib...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                       string_titles  \\\n",
       "0  Russo Cam A watery look North Shore secret soc...   \n",
       "1  Watch Meet Kehu Butler 20 Year Old Rising Surf...   \n",
       "2         With No 2020 Olympics How Surfers Feeling    \n",
       "3  Watch Tom Carroll Matt Grainger Break Down Tow...   \n",
       "4  A Powerful South SSE Groundswell Is About To R...   \n",
       "\n",
       "                                         string_copy  \\\n",
       "0  On clear winter day balmy coastline Oahu North...   \n",
       "1  If know Kehu Butler yet better way get acquain...   \n",
       "2  Two historic things Surfing inaugural debut Ol...   \n",
       "3  We got kinds reef around play When two time Wo...   \n",
       "4  The month January exactly renowned big south s...   \n",
       "\n",
       "                                  string_tags  word_count  \\\n",
       "0            CBD Daniel Russo InnerG pipeline         197   \n",
       "1                                         NaN         105   \n",
       "2  ISA Jordy Smith Olympics sally fitzgibbons         280   \n",
       "3                                         NaN         148   \n",
       "4                                         NaN         514   \n",
       "\n",
       "                                      wordcount_list  \\\n",
       "0  {'clear': 1, 'winter': 1, 'day': 1, 'balmy': 1...   \n",
       "1  {'know': 1, 'kehu': 1, 'butler': 1, 'yet': 1, ...   \n",
       "2  {'historic': 1, 'things': 1, 'surfing': 7, 'in...   \n",
       "3  {'got': 1, 'kinds': 1, 'reef': 1, 'around': 2,...   \n",
       "4  {'month': 2, 'january': 2, 'exactly': 1, 'reno...   \n",
       "\n",
       "                                             tokens2  \\\n",
       "0  [On, clear, winter, day, balmy, coastline, Oah...   \n",
       "1  [If, know, Kehu, Butler, yet, better, way, get...   \n",
       "2  [Two, historic, things, Surfing, inaugural, de...   \n",
       "3  [We, got, kinds, reef, around, play, When, two...   \n",
       "4  [The, month, January, exactly, renowned, big, ...   \n",
       "\n",
       "                                     word_and_scores  \\\n",
       "0  [(On, 5.56), (clear, 6.3), (winter, 5.9), (day...   \n",
       "1  [(If, 4.66), (know, 6.1), (Butler, 5.38), (yet...   \n",
       "2  [(Two, 5.4), (historic, 5.92), (things, 5.76),...   \n",
       "3  [(We, 6.38), (got, 5.6), (kinds, 5.74), (aroun...   \n",
       "4  [(The, 4.98), (month, 5.18), (January, 5.7), (...   \n",
       "\n",
       "                                         scores_only  avg_scores  sum_scores  \n",
       "0  [5.56, 6.3, 5.9, 6.24, 5.52, 6.42, 5.54, 4.98,...    5.955796      935.06  \n",
       "1  [4.66, 6.1, 5.38, 4.7, 7.0, 5.24, 5.92, 6.08, ...    5.935181      492.62  \n",
       "2  [5.4, 5.92, 5.76, 6.14, 7.02, 7.02, 3.34, 5.38...    5.728482     1283.18  \n",
       "3  [6.38, 5.6, 5.74, 5.62, 7.26, 4.96, 5.4, 5.74,...    5.787257      653.96  \n",
       "4  [4.98, 5.18, 5.7, 6.0, 6.22, 6.16, 5.74, 5.38,...    5.630883     2167.89  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>dates</th>\n      <th>tokenized_title</th>\n      <th>tokenized_copy</th>\n      <th>tags_text</th>\n      <th>string_titles</th>\n      <th>string_copy</th>\n      <th>string_tags</th>\n      <th>word_count</th>\n      <th>wordcount_list</th>\n      <th>tokens2</th>\n      <th>word_and_scores</th>\n      <th>scores_only</th>\n      <th>avg_scores</th>\n      <th>sum_scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>['Russo', 'Cam', 'A', 'watery', 'look', 'North...</td>\n      <td>['On', 'clear', 'winter', 'day', 'balmy', 'coa...</td>\n      <td>[\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]</td>\n      <td>Russo Cam A watery look North Shore secret soc...</td>\n      <td>On clear winter day balmy coastline Oahu North...</td>\n      <td>CBD Daniel Russo InnerG pipeline</td>\n      <td>197</td>\n      <td>{'clear': 1, 'winter': 1, 'day': 1, 'balmy': 1...</td>\n      <td>[On, clear, winter, day, balmy, coastline, Oah...</td>\n      <td>[(On, 5.56), (clear, 6.3), (winter, 5.9), (day...</td>\n      <td>[5.56, 6.3, 5.9, 6.24, 5.52, 6.42, 5.54, 4.98,...</td>\n      <td>5.955796</td>\n      <td>935.06</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2020-11-02</td>\n      <td>['Watch', 'Meet', 'Kehu', 'Butler', '20', 'Yea...</td>\n      <td>['If', 'know', 'Kehu', 'Butler', 'yet', 'bette...</td>\n      <td>[]</td>\n      <td>Watch Meet Kehu Butler 20 Year Old Rising Surf...</td>\n      <td>If know Kehu Butler yet better way get acquain...</td>\n      <td>NaN</td>\n      <td>105</td>\n      <td>{'know': 1, 'kehu': 1, 'butler': 1, 'yet': 1, ...</td>\n      <td>[If, know, Kehu, Butler, yet, better, way, get...</td>\n      <td>[(If, 4.66), (know, 6.1), (Butler, 5.38), (yet...</td>\n      <td>[4.66, 6.1, 5.38, 4.7, 7.0, 5.24, 5.92, 6.08, ...</td>\n      <td>5.935181</td>\n      <td>492.62</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2020-10-17</td>\n      <td>['With', 'No', '2020', 'Olympics', 'How', 'Sur...</td>\n      <td>['Two', 'historic', 'things', 'Surfing', 'inau...</td>\n      <td>[\"ISA\",\"Jordy Smith\",\"Olympics\",\"sally fitzgib...</td>\n      <td>With No 2020 Olympics How Surfers Feeling</td>\n      <td>Two historic things Surfing inaugural debut Ol...</td>\n      <td>ISA Jordy Smith Olympics sally fitzgibbons</td>\n      <td>280</td>\n      <td>{'historic': 1, 'things': 1, 'surfing': 7, 'in...</td>\n      <td>[Two, historic, things, Surfing, inaugural, de...</td>\n      <td>[(Two, 5.4), (historic, 5.92), (things, 5.76),...</td>\n      <td>[5.4, 5.92, 5.76, 6.14, 7.02, 7.02, 3.34, 5.38...</td>\n      <td>5.728482</td>\n      <td>1283.18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2020-10-13</td>\n      <td>['Watch', 'Tom', 'Carroll', 'Matt', 'Grainger'...</td>\n      <td>['We', 'got', 'kinds', 'reef', 'around', 'play...</td>\n      <td>[]</td>\n      <td>Watch Tom Carroll Matt Grainger Break Down Tow...</td>\n      <td>We got kinds reef around play When two time Wo...</td>\n      <td>NaN</td>\n      <td>148</td>\n      <td>{'got': 1, 'kinds': 1, 'reef': 1, 'around': 2,...</td>\n      <td>[We, got, kinds, reef, around, play, When, two...</td>\n      <td>[(We, 6.38), (got, 5.6), (kinds, 5.74), (aroun...</td>\n      <td>[6.38, 5.6, 5.74, 5.62, 7.26, 4.96, 5.4, 5.74,...</td>\n      <td>5.787257</td>\n      <td>653.96</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2021-01-18</td>\n      <td>['A', 'Powerful', 'South', 'SSE', 'Groundswell...</td>\n      <td>['The', 'month', 'January', 'exactly', 'renown...</td>\n      <td>[]</td>\n      <td>A Powerful South SSE Groundswell Is About To R...</td>\n      <td>The month January exactly renowned big south s...</td>\n      <td>NaN</td>\n      <td>514</td>\n      <td>{'month': 2, 'january': 2, 'exactly': 1, 'reno...</td>\n      <td>[The, month, January, exactly, renowned, big, ...</td>\n      <td>[(The, 4.98), (month, 5.18), (January, 5.7), (...</td>\n      <td>[4.98, 5.18, 5.7, 6.0, 6.22, 6.16, 5.74, 5.38,...</td>\n      <td>5.630883</td>\n      <td>2167.89</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "# Append token list to dataframe\n",
    "df['tokens2'] = tokens\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## Find Sentiment Score of Each Word"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Look through the tokens list and access the value of the word with .loc()\n",
    "# Append words in a tweet list, then append that list to the scores list\n",
    "# Make sure to turn all words into lowercase first to match the hedo_df words\n",
    "word_and_scores = []\n",
    "for token in tokens:\n",
    "    tweet = []\n",
    "    for word in token:\n",
    "        score = hedo_df.loc[hedo_df['word'] == word.lower(), 'happs']\n",
    "        if score.values.size:\n",
    "            tweet.append((word, score.values[0]))\n",
    "            # print(word,score.values[0])\n",
    "    word_and_scores.append(tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('On', 5.56), ('clear', 6.3), ('winter', 5.9), ('day', 6.24), ('North', 5.52)]"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "# Inspect the list of words and scores\n",
    "word_and_scores[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate only the scores of the individual words of each tweet in list of lists\n",
    "scores_only = []\n",
    "for token in tokens:\n",
    "    tweet = []\n",
    "    for word in token:\n",
    "        score = hedo_df.loc[hedo_df['word'] == word.lower(), 'happs']\n",
    "        if score.values.size:\n",
    "            tweet.append(score.values[0])\n",
    "#             print(score.values[0])\n",
    "    scores_only.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[5.56, 6.3, 5.9, 6.24, 5.52]"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "# inspect\n",
    "scores_only[0][0:5]"
   ]
  },
  {
   "source": [
    "## Find Sum and Mean Scores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to .agg() a new colum with mean and sum? \n",
    "import statistics as st\n",
    "sum_scores = [sum(x) for x in scores_only]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[935.0600000000003,\n",
       " 492.62000000000006,\n",
       " 1283.1799999999994,\n",
       " 653.9600000000003,\n",
       " 2167.8900000000026]"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "sum_scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate mean you must create a function with a try/except logic for 'nan' values\n",
    "def check(data):\n",
    "    try:\n",
    "        return st.mean(data)\n",
    "    except:\n",
    "        return np.nan\n",
    "avg_scores = [check(x) for x in scores_only]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[5.955796178343949,\n",
       " 5.935180722891566,\n",
       " 5.728482142857143,\n",
       " 5.7872566371681415,\n",
       " 5.630883116883117]"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "avg_scores[:5]"
   ]
  },
  {
   "source": [
    "## Append To the Dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0       dates                                    tokenized_title  \\\n",
       "0           0         NaN  ['Russo', 'Cam', 'A', 'watery', 'look', 'North...   \n",
       "1           1  2020-11-02  ['Watch', 'Meet', 'Kehu', 'Butler', '20', 'Yea...   \n",
       "2           2  2020-10-17  ['With', 'No', '2020', 'Olympics', 'How', 'Sur...   \n",
       "3           3  2020-10-13  ['Watch', 'Tom', 'Carroll', 'Matt', 'Grainger'...   \n",
       "4           4  2021-01-18  ['A', 'Powerful', 'South', 'SSE', 'Groundswell...   \n",
       "\n",
       "                                      tokenized_copy  \\\n",
       "0  ['On', 'clear', 'winter', 'day', 'balmy', 'coa...   \n",
       "1  ['If', 'know', 'Kehu', 'Butler', 'yet', 'bette...   \n",
       "2  ['Two', 'historic', 'things', 'Surfing', 'inau...   \n",
       "3  ['We', 'got', 'kinds', 'reef', 'around', 'play...   \n",
       "4  ['The', 'month', 'January', 'exactly', 'renown...   \n",
       "\n",
       "                                           tags_text  \\\n",
       "0         [\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]   \n",
       "1                                                 []   \n",
       "2  [\"ISA\",\"Jordy Smith\",\"Olympics\",\"sally fitzgib...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                       string_titles  \\\n",
       "0  Russo Cam A watery look North Shore secret soc...   \n",
       "1  Watch Meet Kehu Butler 20 Year Old Rising Surf...   \n",
       "2         With No 2020 Olympics How Surfers Feeling    \n",
       "3  Watch Tom Carroll Matt Grainger Break Down Tow...   \n",
       "4  A Powerful South SSE Groundswell Is About To R...   \n",
       "\n",
       "                                         string_copy  \\\n",
       "0  On clear winter day balmy coastline Oahu North...   \n",
       "1  If know Kehu Butler yet better way get acquain...   \n",
       "2  Two historic things Surfing inaugural debut Ol...   \n",
       "3  We got kinds reef around play When two time Wo...   \n",
       "4  The month January exactly renowned big south s...   \n",
       "\n",
       "                                  string_tags  word_count  \\\n",
       "0            CBD Daniel Russo InnerG pipeline         197   \n",
       "1                                         NaN         105   \n",
       "2  ISA Jordy Smith Olympics sally fitzgibbons         280   \n",
       "3                                         NaN         148   \n",
       "4                                         NaN         514   \n",
       "\n",
       "                                      wordcount_list  \\\n",
       "0  {'clear': 1, 'winter': 1, 'day': 1, 'balmy': 1...   \n",
       "1  {'know': 1, 'kehu': 1, 'butler': 1, 'yet': 1, ...   \n",
       "2  {'historic': 1, 'things': 1, 'surfing': 7, 'in...   \n",
       "3  {'got': 1, 'kinds': 1, 'reef': 1, 'around': 2,...   \n",
       "4  {'month': 2, 'january': 2, 'exactly': 1, 'reno...   \n",
       "\n",
       "                                             tokens2  \\\n",
       "0  [On, clear, winter, day, balmy, coastline, Oah...   \n",
       "1  [If, know, Kehu, Butler, yet, better, way, get...   \n",
       "2  [Two, historic, things, Surfing, inaugural, de...   \n",
       "3  [We, got, kinds, reef, around, play, When, two...   \n",
       "4  [The, month, January, exactly, renowned, big, ...   \n",
       "\n",
       "                                     word_and_scores  \\\n",
       "0  [(On, 5.56), (clear, 6.3), (winter, 5.9), (day...   \n",
       "1  [(If, 4.66), (know, 6.1), (Butler, 5.38), (yet...   \n",
       "2  [(Two, 5.4), (historic, 5.92), (things, 5.76),...   \n",
       "3  [(We, 6.38), (got, 5.6), (kinds, 5.74), (aroun...   \n",
       "4  [(The, 4.98), (month, 5.18), (January, 5.7), (...   \n",
       "\n",
       "                                         scores_only  avg_scores  sum_scores  \n",
       "0  [5.56, 6.3, 5.9, 6.24, 5.52, 6.42, 5.54, 4.98,...    5.955796      935.06  \n",
       "1  [4.66, 6.1, 5.38, 4.7, 7.0, 5.24, 5.92, 6.08, ...    5.935181      492.62  \n",
       "2  [5.4, 5.92, 5.76, 6.14, 7.02, 7.02, 3.34, 5.38...    5.728482     1283.18  \n",
       "3  [6.38, 5.6, 5.74, 5.62, 7.26, 4.96, 5.4, 5.74,...    5.787257      653.96  \n",
       "4  [4.98, 5.18, 5.7, 6.0, 6.22, 6.16, 5.74, 5.38,...    5.630883     2167.89  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>dates</th>\n      <th>tokenized_title</th>\n      <th>tokenized_copy</th>\n      <th>tags_text</th>\n      <th>string_titles</th>\n      <th>string_copy</th>\n      <th>string_tags</th>\n      <th>word_count</th>\n      <th>wordcount_list</th>\n      <th>tokens2</th>\n      <th>word_and_scores</th>\n      <th>scores_only</th>\n      <th>avg_scores</th>\n      <th>sum_scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>['Russo', 'Cam', 'A', 'watery', 'look', 'North...</td>\n      <td>['On', 'clear', 'winter', 'day', 'balmy', 'coa...</td>\n      <td>[\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]</td>\n      <td>Russo Cam A watery look North Shore secret soc...</td>\n      <td>On clear winter day balmy coastline Oahu North...</td>\n      <td>CBD Daniel Russo InnerG pipeline</td>\n      <td>197</td>\n      <td>{'clear': 1, 'winter': 1, 'day': 1, 'balmy': 1...</td>\n      <td>[On, clear, winter, day, balmy, coastline, Oah...</td>\n      <td>[(On, 5.56), (clear, 6.3), (winter, 5.9), (day...</td>\n      <td>[5.56, 6.3, 5.9, 6.24, 5.52, 6.42, 5.54, 4.98,...</td>\n      <td>5.955796</td>\n      <td>935.06</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2020-11-02</td>\n      <td>['Watch', 'Meet', 'Kehu', 'Butler', '20', 'Yea...</td>\n      <td>['If', 'know', 'Kehu', 'Butler', 'yet', 'bette...</td>\n      <td>[]</td>\n      <td>Watch Meet Kehu Butler 20 Year Old Rising Surf...</td>\n      <td>If know Kehu Butler yet better way get acquain...</td>\n      <td>NaN</td>\n      <td>105</td>\n      <td>{'know': 1, 'kehu': 1, 'butler': 1, 'yet': 1, ...</td>\n      <td>[If, know, Kehu, Butler, yet, better, way, get...</td>\n      <td>[(If, 4.66), (know, 6.1), (Butler, 5.38), (yet...</td>\n      <td>[4.66, 6.1, 5.38, 4.7, 7.0, 5.24, 5.92, 6.08, ...</td>\n      <td>5.935181</td>\n      <td>492.62</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2020-10-17</td>\n      <td>['With', 'No', '2020', 'Olympics', 'How', 'Sur...</td>\n      <td>['Two', 'historic', 'things', 'Surfing', 'inau...</td>\n      <td>[\"ISA\",\"Jordy Smith\",\"Olympics\",\"sally fitzgib...</td>\n      <td>With No 2020 Olympics How Surfers Feeling</td>\n      <td>Two historic things Surfing inaugural debut Ol...</td>\n      <td>ISA Jordy Smith Olympics sally fitzgibbons</td>\n      <td>280</td>\n      <td>{'historic': 1, 'things': 1, 'surfing': 7, 'in...</td>\n      <td>[Two, historic, things, Surfing, inaugural, de...</td>\n      <td>[(Two, 5.4), (historic, 5.92), (things, 5.76),...</td>\n      <td>[5.4, 5.92, 5.76, 6.14, 7.02, 7.02, 3.34, 5.38...</td>\n      <td>5.728482</td>\n      <td>1283.18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2020-10-13</td>\n      <td>['Watch', 'Tom', 'Carroll', 'Matt', 'Grainger'...</td>\n      <td>['We', 'got', 'kinds', 'reef', 'around', 'play...</td>\n      <td>[]</td>\n      <td>Watch Tom Carroll Matt Grainger Break Down Tow...</td>\n      <td>We got kinds reef around play When two time Wo...</td>\n      <td>NaN</td>\n      <td>148</td>\n      <td>{'got': 1, 'kinds': 1, 'reef': 1, 'around': 2,...</td>\n      <td>[We, got, kinds, reef, around, play, When, two...</td>\n      <td>[(We, 6.38), (got, 5.6), (kinds, 5.74), (aroun...</td>\n      <td>[6.38, 5.6, 5.74, 5.62, 7.26, 4.96, 5.4, 5.74,...</td>\n      <td>5.787257</td>\n      <td>653.96</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2021-01-18</td>\n      <td>['A', 'Powerful', 'South', 'SSE', 'Groundswell...</td>\n      <td>['The', 'month', 'January', 'exactly', 'renown...</td>\n      <td>[]</td>\n      <td>A Powerful South SSE Groundswell Is About To R...</td>\n      <td>The month January exactly renowned big south s...</td>\n      <td>NaN</td>\n      <td>514</td>\n      <td>{'month': 2, 'january': 2, 'exactly': 1, 'reno...</td>\n      <td>[The, month, January, exactly, renowned, big, ...</td>\n      <td>[(The, 4.98), (month, 5.18), (January, 5.7), (...</td>\n      <td>[4.98, 5.18, 5.7, 6.0, 6.22, 6.16, 5.74, 5.38,...</td>\n      <td>5.630883</td>\n      <td>2167.89</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "# Inspect the DF with the newly added columns\n",
    "df['word_and_scores'] = word_and_scores\n",
    "df['scores_only'] = scores_only\n",
    "df['avg_scores'] = avg_scores\n",
    "df['sum_scores'] = sum_scores\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/nlp_sentiment.csv', index=False)"
   ]
  },
  {
   "source": [
    "## Find Overall Average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Avegerage score of all words: 5.67\n"
     ]
    }
   ],
   "source": [
    "total_avg_score = 5.67\n",
    "print(f'Avegerage score of all words: {total_avg_score}')"
   ]
  }
 ]
}