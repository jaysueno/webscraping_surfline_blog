{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Cleanup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\jaysu\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\jaysu\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 242
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "# Use nltk for tokenizer and stopwords removal\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/surfline_news_scrape.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(85, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 244
    }
   ],
   "source": [
    "df = df[['date', 'title', 'tags_text', 'p_text']]\n",
    "df.shape"
   ]
  },
  {
   "source": [
    "# Cleanup the data field"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                 []\n",
       "1      Nov 2nd, 2020\n",
       "2     Oct 17th, 2020\n",
       "3     Oct 13th, 2020\n",
       "4     Jan 18th, 2021\n",
       "           ...      \n",
       "80    Jan 15th, 2021\n",
       "81    Jan 15th, 2021\n",
       "82    Jan 17th, 2021\n",
       "83    Jan 18th, 2021\n",
       "84    Jan 15th, 2021\n",
       "Name: date, Length: 85, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 245
    }
   ],
   "source": [
    "df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Datetime string example:\nNov 2nd, 2020\n"
     ]
    }
   ],
   "source": [
    "test_date = df['date'][1]\n",
    "print('Datetime string example:')\n",
    "print(df['date'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                 []\n",
       "1      Nov 2nd, 2020\n",
       "2     Oct 17th, 2020\n",
       "3     Oct 13th, 2020\n",
       "4     Jan 18th, 2021\n",
       "           ...      \n",
       "80    Jan 15th, 2021\n",
       "81    Jan 15th, 2021\n",
       "82    Jan 17th, 2021\n",
       "83    Jan 18th, 2021\n",
       "84    Jan 15th, 2021\n",
       "Name: date, Length: 85, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 247
    }
   ],
   "source": [
    "date_array = df['date']\n",
    "date_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "dates = []\n",
    "for item in date_array:\n",
    "    try:\n",
    "        date = str(parse(item))\n",
    "        date2 = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "        date3 = date2.strftime('%Y-%m-%d')\n",
    "        dates.append(date3)\n",
    "        # print(date2.date())\n",
    "    except:\n",
    "        dates.append('n/a')\n",
    "\n",
    "article_date = {'article_date': dates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "metadata": {},
     "execution_count": 249
    }
   ],
   "source": [
    "len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dates'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         dates                                              title  \\\n",
       "0          n/a  Russo Cam: A watery look into the North Shore’...   \n",
       "1   2020-11-02  Watch: Meet Kehu Butler, the 20-Year-Old Risin...   \n",
       "2   2020-10-17  With No 2020 Olympics, How're the Surfers Feel...   \n",
       "3   2020-10-13  Watch Tom Carroll & Matt Grainger Break Down T...   \n",
       "4   2021-01-18  A Powerful South and SSE Groundswell Is About ...   \n",
       "..         ...                                                ...   \n",
       "80  2021-01-15  Pre-Game Swell Hits Hawaii; \"Preheats Oven\" fo...   \n",
       "81  2021-01-15  How Will Jaws Stack Up? Comparing Pe’ahi‘s Gre...   \n",
       "82  2021-01-17  Replay: Live From Jaws and Waimea on Super Swe...   \n",
       "83  2021-01-18                        R.I.P. Ben Aipa (1942-2021)   \n",
       "84  2021-01-15  A Ripping New Rage Vid, Pete Mel's Stoke Is Ev...   \n",
       "\n",
       "                                               p_text  \\\n",
       "0   [\"Quickly access the spots you care about most...   \n",
       "1   [\"Quickly access the spots you care about most...   \n",
       "2   [\"Quickly access the spots you care about most...   \n",
       "3   [\"Quickly access the spots you care about most...   \n",
       "4   [\"Quickly access the spots you care about most...   \n",
       "..                                                ...   \n",
       "80  [\"Quickly access the spots you care about most...   \n",
       "81  [\"Quickly access the spots you care about most...   \n",
       "82  [\"Quickly access the spots you care about most...   \n",
       "83  [\"Quickly access the spots you care about most...   \n",
       "84  [\"Quickly access the spots you care about most...   \n",
       "\n",
       "                                            tags_text  \n",
       "0          [\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]  \n",
       "1                                                  []  \n",
       "2   [\"ISA\",\"Jordy Smith\",\"Olympics\",\"sally fitzgib...  \n",
       "3                                                  []  \n",
       "4                                                  []  \n",
       "..                                                ...  \n",
       "80                                  [\"swell stories\"]  \n",
       "81                                           [\"Jaws\"]  \n",
       "82                           [\"Jaws\",\"surfline live\"]  \n",
       "83            [\"Ben Aipa\",\"Hawaii\",\"r.i.p.\",\"shaper\"]  \n",
       "84                                                 []  \n",
       "\n",
       "[85 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dates</th>\n      <th>title</th>\n      <th>p_text</th>\n      <th>tags_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n/a</td>\n      <td>Russo Cam: A watery look into the North Shore’...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-11-02</td>\n      <td>Watch: Meet Kehu Butler, the 20-Year-Old Risin...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-10-17</td>\n      <td>With No 2020 Olympics, How're the Surfers Feel...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[\"ISA\",\"Jordy Smith\",\"Olympics\",\"sally fitzgib...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-10-13</td>\n      <td>Watch Tom Carroll &amp; Matt Grainger Break Down T...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-01-18</td>\n      <td>A Powerful South and SSE Groundswell Is About ...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>2021-01-15</td>\n      <td>Pre-Game Swell Hits Hawaii; \"Preheats Oven\" fo...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[\"swell stories\"]</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>2021-01-15</td>\n      <td>How Will Jaws Stack Up? Comparing Pe’ahi‘s Gre...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[\"Jaws\"]</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>2021-01-17</td>\n      <td>Replay: Live From Jaws and Waimea on Super Swe...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[\"Jaws\",\"surfline live\"]</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>2021-01-18</td>\n      <td>R.I.P. Ben Aipa (1942-2021)</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[\"Ben Aipa\",\"Hawaii\",\"r.i.p.\",\"shaper\"]</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>2021-01-15</td>\n      <td>A Ripping New Rage Vid, Pete Mel's Stoke Is Ev...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>85 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 251
    }
   ],
   "source": [
    "df = df[['dates', 'title', 'p_text', 'tags_text']]\n",
    "df"
   ]
  },
  {
   "source": [
    "# Clean News Article Copy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_list = []\n",
    "for text1 in df['p_text']:\n",
    "    # text_list = []\n",
    "    string = \"Quickly access the spots you care about most.\"\n",
    "    new_str = text1.replace(string, '')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    word_tokens = tokenizer.tokenize(new_str)\n",
    "    filtered_string = [w for w in word_tokens if not w in stop_words]\n",
    "    # print(new_words)\n",
    "    text_list.append(filtered_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = []\n",
    "for text2 in df['title']:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    word_tokens = tokenizer.tokenize(text2)\n",
    "    filtered_string = [w for w in word_tokens if not w in stop_words]\n",
    "    title_list.append(filtered_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(df.tail(1).index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_copy'] = text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_title'] = title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(85, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 280
    }
   ],
   "source": [
    "df2 = df[['dates', 'tokenized_title', 'tokenized_copy', 'tags_text']]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        dates                                    tokenized_title  \\\n",
       "0         n/a  [Russo, Cam, A, watery, look, North, Shore, se...   \n",
       "1  2020-11-02  [Watch, Meet, Kehu, Butler, 20, Year, Old, Ris...   \n",
       "2  2020-10-17  [With, No, 2020, Olympics, How, Surfers, Feeling]   \n",
       "3  2020-10-13  [Watch, Tom, Carroll, Matt, Grainger, Break, D...   \n",
       "4  2021-01-18  [A, Powerful, South, SSE, Groundswell, Is, Abo...   \n",
       "\n",
       "                                      tokenized_copy  \\\n",
       "0  [On, clear, winter, day, balmy, coastline, Oah...   \n",
       "1  [If, know, Kehu, Butler, yet, better, way, get...   \n",
       "2  [Two, historic, things, Surfing, inaugural, de...   \n",
       "3  [We, got, kinds, reef, around, play, When, two...   \n",
       "4  [The, month, January, exactly, renowned, big, ...   \n",
       "\n",
       "                                           tags_text  \n",
       "0         [\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]  \n",
       "1                                                 []  \n",
       "2  [\"ISA\",\"Jordy Smith\",\"Olympics\",\"sally fitzgib...  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dates</th>\n      <th>tokenized_title</th>\n      <th>tokenized_copy</th>\n      <th>tags_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n/a</td>\n      <td>[Russo, Cam, A, watery, look, North, Shore, se...</td>\n      <td>[On, clear, winter, day, balmy, coastline, Oah...</td>\n      <td>[\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-11-02</td>\n      <td>[Watch, Meet, Kehu, Butler, 20, Year, Old, Ris...</td>\n      <td>[If, know, Kehu, Butler, yet, better, way, get...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-10-17</td>\n      <td>[With, No, 2020, Olympics, How, Surfers, Feeling]</td>\n      <td>[Two, historic, things, Surfing, inaugural, de...</td>\n      <td>[\"ISA\",\"Jordy Smith\",\"Olympics\",\"sally fitzgib...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-10-13</td>\n      <td>[Watch, Tom, Carroll, Matt, Grainger, Break, D...</td>\n      <td>[We, got, kinds, reef, around, play, When, two...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-01-18</td>\n      <td>[A, Powerful, South, SSE, Groundswell, Is, Abo...</td>\n      <td>[The, month, January, exactly, renowned, big, ...</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 281
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}