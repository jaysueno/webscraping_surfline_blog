{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Cleanup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\jaysu\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\jaysu\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "# Use nltk for tokenizer and stopwords removal\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/surfline_news_scrape.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(85, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df = df[['date', 'title', 'tags_text', 'p_text']]\n",
    "df.shape"
   ]
  },
  {
   "source": [
    "# Cleanup the data field"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                 []\n",
       "1      Nov 2nd, 2020\n",
       "2     Oct 17th, 2020\n",
       "3     Oct 13th, 2020\n",
       "4     Jan 18th, 2021\n",
       "           ...      \n",
       "80    Jan 15th, 2021\n",
       "81    Jan 15th, 2021\n",
       "82    Jan 17th, 2021\n",
       "83    Jan 18th, 2021\n",
       "84    Jan 15th, 2021\n",
       "Name: date, Length: 85, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Datetime string example:\nNov 2nd, 2020\n"
     ]
    }
   ],
   "source": [
    "test_date = df['date'][1]\n",
    "print('Datetime string example:')\n",
    "print(df['date'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                 []\n",
       "1      Nov 2nd, 2020\n",
       "2     Oct 17th, 2020\n",
       "3     Oct 13th, 2020\n",
       "4     Jan 18th, 2021\n",
       "           ...      \n",
       "80    Jan 15th, 2021\n",
       "81    Jan 15th, 2021\n",
       "82    Jan 17th, 2021\n",
       "83    Jan 18th, 2021\n",
       "84    Jan 15th, 2021\n",
       "Name: date, Length: 85, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "date_array = df['date']\n",
    "date_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "dates = []\n",
    "for item in date_array:\n",
    "    try:\n",
    "        date = str(parse(item))\n",
    "        date2 = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "        date3 = date2.strftime('%Y-%m-%d')\n",
    "        dates.append(date3)\n",
    "        # print(date2.date())\n",
    "    except:\n",
    "        dates.append('n/a')\n",
    "\n",
    "article_date = {'article_date': dates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dates'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         dates                                              title  \\\n",
       "0          n/a  Russo Cam: A watery look into the North Shore’...   \n",
       "1   2020-11-02  Watch: Meet Kehu Butler, the 20-Year-Old Risin...   \n",
       "2   2020-10-17  With No 2020 Olympics, How're the Surfers Feel...   \n",
       "3   2020-10-13  Watch Tom Carroll & Matt Grainger Break Down T...   \n",
       "4   2021-01-18  A Powerful South and SSE Groundswell Is About ...   \n",
       "..         ...                                                ...   \n",
       "80  2021-01-15  Pre-Game Swell Hits Hawaii; \"Preheats Oven\" fo...   \n",
       "81  2021-01-15  How Will Jaws Stack Up? Comparing Pe’ahi‘s Gre...   \n",
       "82  2021-01-17  Replay: Live From Jaws and Waimea on Super Swe...   \n",
       "83  2021-01-18                        R.I.P. Ben Aipa (1942-2021)   \n",
       "84  2021-01-15  A Ripping New Rage Vid, Pete Mel's Stoke Is Ev...   \n",
       "\n",
       "                                               p_text  \\\n",
       "0   [\"Quickly access the spots you care about most...   \n",
       "1   [\"Quickly access the spots you care about most...   \n",
       "2   [\"Quickly access the spots you care about most...   \n",
       "3   [\"Quickly access the spots you care about most...   \n",
       "4   [\"Quickly access the spots you care about most...   \n",
       "..                                                ...   \n",
       "80  [\"Quickly access the spots you care about most...   \n",
       "81  [\"Quickly access the spots you care about most...   \n",
       "82  [\"Quickly access the spots you care about most...   \n",
       "83  [\"Quickly access the spots you care about most...   \n",
       "84  [\"Quickly access the spots you care about most...   \n",
       "\n",
       "                                            tags_text  \n",
       "0          [\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]  \n",
       "1                                                  []  \n",
       "2   [\"ISA\",\"Jordy Smith\",\"Olympics\",\"sally fitzgib...  \n",
       "3                                                  []  \n",
       "4                                                  []  \n",
       "..                                                ...  \n",
       "80                                  [\"swell stories\"]  \n",
       "81                                           [\"Jaws\"]  \n",
       "82                           [\"Jaws\",\"surfline live\"]  \n",
       "83            [\"Ben Aipa\",\"Hawaii\",\"r.i.p.\",\"shaper\"]  \n",
       "84                                                 []  \n",
       "\n",
       "[85 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dates</th>\n      <th>title</th>\n      <th>p_text</th>\n      <th>tags_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n/a</td>\n      <td>Russo Cam: A watery look into the North Shore’...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-11-02</td>\n      <td>Watch: Meet Kehu Butler, the 20-Year-Old Risin...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-10-17</td>\n      <td>With No 2020 Olympics, How're the Surfers Feel...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[\"ISA\",\"Jordy Smith\",\"Olympics\",\"sally fitzgib...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-10-13</td>\n      <td>Watch Tom Carroll &amp; Matt Grainger Break Down T...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-01-18</td>\n      <td>A Powerful South and SSE Groundswell Is About ...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>2021-01-15</td>\n      <td>Pre-Game Swell Hits Hawaii; \"Preheats Oven\" fo...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[\"swell stories\"]</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>2021-01-15</td>\n      <td>How Will Jaws Stack Up? Comparing Pe’ahi‘s Gre...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[\"Jaws\"]</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>2021-01-17</td>\n      <td>Replay: Live From Jaws and Waimea on Super Swe...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[\"Jaws\",\"surfline live\"]</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>2021-01-18</td>\n      <td>R.I.P. Ben Aipa (1942-2021)</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[\"Ben Aipa\",\"Hawaii\",\"r.i.p.\",\"shaper\"]</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>2021-01-15</td>\n      <td>A Ripping New Rage Vid, Pete Mel's Stoke Is Ev...</td>\n      <td>[\"Quickly access the spots you care about most...</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>85 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df = df[['dates', 'title', 'p_text', 'tags_text']]\n",
    "df"
   ]
  },
  {
   "source": [
    "# Clean News Article Copy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_list = []\n",
    "for text1 in df['p_text']:\n",
    "    # text_list = []\n",
    "    string = \"Quickly access the spots you care about most.\"\n",
    "    new_str = text1.replace(string, '')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    word_tokens = tokenizer.tokenize(new_str)\n",
    "    filtered_string = [w for w in word_tokens if not w in stop_words]\n",
    "    # print(new_words)\n",
    "    text_list.append(filtered_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = []\n",
    "for text2 in df['title']:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    word_tokens = tokenizer.tokenize(text2)\n",
    "    filtered_string = [w for w in word_tokens if not w in stop_words]\n",
    "    title_list.append(filtered_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(df.tail(1).index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_copy'] = text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_title'] = title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(85, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "df2 = df[['dates', 'tokenized_title', 'tokenized_copy', 'tags_text']]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        dates                                    tokenized_title  \\\n",
       "0         n/a  [Russo, Cam, A, watery, look, North, Shore, se...   \n",
       "1  2020-11-02  [Watch, Meet, Kehu, Butler, 20, Year, Old, Ris...   \n",
       "2  2020-10-17  [With, No, 2020, Olympics, How, Surfers, Feeling]   \n",
       "3  2020-10-13  [Watch, Tom, Carroll, Matt, Grainger, Break, D...   \n",
       "4  2021-01-18  [A, Powerful, South, SSE, Groundswell, Is, Abo...   \n",
       "\n",
       "                                      tokenized_copy  \\\n",
       "0  [On, clear, winter, day, balmy, coastline, Oah...   \n",
       "1  [If, know, Kehu, Butler, yet, better, way, get...   \n",
       "2  [Two, historic, things, Surfing, inaugural, de...   \n",
       "3  [We, got, kinds, reef, around, play, When, two...   \n",
       "4  [The, month, January, exactly, renowned, big, ...   \n",
       "\n",
       "                                           tags_text  \n",
       "0         [\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]  \n",
       "1                                                 []  \n",
       "2  [\"ISA\",\"Jordy Smith\",\"Olympics\",\"sally fitzgib...  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dates</th>\n      <th>tokenized_title</th>\n      <th>tokenized_copy</th>\n      <th>tags_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n/a</td>\n      <td>[Russo, Cam, A, watery, look, North, Shore, se...</td>\n      <td>[On, clear, winter, day, balmy, coastline, Oah...</td>\n      <td>[\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-11-02</td>\n      <td>[Watch, Meet, Kehu, Butler, 20, Year, Old, Ris...</td>\n      <td>[If, know, Kehu, Butler, yet, better, way, get...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-10-17</td>\n      <td>[With, No, 2020, Olympics, How, Surfers, Feeling]</td>\n      <td>[Two, historic, things, Surfing, inaugural, de...</td>\n      <td>[\"ISA\",\"Jordy Smith\",\"Olympics\",\"sally fitzgib...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-10-13</td>\n      <td>[Watch, Tom, Carroll, Matt, Grainger, Break, D...</td>\n      <td>[We, got, kinds, reef, around, play, When, two...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-01-18</td>\n      <td>[A, Powerful, South, SSE, Groundswell, Is, Abo...</td>\n      <td>[The, month, January, exactly, renowned, big, ...</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('data/surfline_clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "def create_string(tokens):\n",
    "    string = ''\n",
    "    for token in tokens:\n",
    "        string += token + ' ' \n",
    "    return string\n",
    "\n",
    "titles_text_lists = df2['tokenized_title']\n",
    "titles_string = [create_string(token_list) for token_list in titles_text_lists]\n",
    "len(titles_string)\n",
    "# titles_string[0]\n",
    "\n",
    "\n",
    "# create_string(text2)\n",
    "# text2 = df2['tokenized_title'][0]\n",
    "# text1 = ''\n",
    "# # text2 = text2.replace(''', '')\n",
    "# for text in text2:\n",
    "#     text1 += text + ' '\n",
    "# text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'On clear winter day balmy coastline Oahu North Shore Daniel Russo floats serenely The sea agitated churning sucking toward horizon Banzai Pipeline crowd scratches toward incoming west set capped slightly Second Reef standing tall slab like brave takers willing turn First Reef behemoth But underground heavies jockey visiting CT pros brazen youth trying make name Daniel holds position treading water one arm clutching heavy water housing bizarre portrait calm feet impact zone world deadliest wave Of course Daniel first rodeo He earned stripes lucky us get intimate look world Inner G newest episode Russo Cam access pass North Shore shot North Shore finest water lensman Daniel Russo Just growing North Shore backyard powerful playground describes Russo And I think drew lifestyle It attraction energy excitement I could see happening beach water I thought pretty cool water photography like secret society artists earn way Certainly D Russo Now press play join journey Because good body good psyche A behind curtain pit underwater series brought InnerG one planet talented water photographers Cross boarding phenom big wave star speaks heart Weeks solid XL surf starts North Shore Northern California Quiet surf begin week bigger swell Christmas That surf boot tho '"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "copy_text_lists = df2['tokenized_copy']\n",
    "copy_string = [create_string(token_list) for token_list in copy_text_lists]\n",
    "copy_string[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\"CBD\",\"Daniel Russo\",\"InnerG\",\"pipeline\"]'"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "tags_text_list = df2['tags_text'][0]\n",
    "text5 = re.sub(r'\\[.*?\\]+', '', tags_text_list)\n",
    "tags_text_list.replace('[', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "85\nCBD Daniel Russo InnerG pipeline\n"
     ]
    }
   ],
   "source": [
    "def clean_str(string):\n",
    "    string = string.replace('[', '')\n",
    "    string = string.replace(']', '')\n",
    "    string = string.replace('\"', '')\n",
    "    string = string.replace(',', ' ')\n",
    "    return string\n",
    "\n",
    "clean_str(tags_text_list)\n",
    "\n",
    "tags_text_list = df2['tags_text']\n",
    "tags_string = [clean_str(token_list) for token_list in tags_text_list]\n",
    "\n",
    "print(len(tags_string))\n",
    "print(tags_string[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}