{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import librarys\n",
    "import pandas as pd \n",
    "import os\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs \n",
    "import datetime as dt\n",
    "import time\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "db = client.surfline_db\n",
    "collection = db.news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Surfline blog page URL\n",
    "url = 'https://www.surfline.com/surf-news'\n",
    "\n",
    "# Retrive the page with the request module\n",
    "response = requests.get(url)\n",
    "\n",
    "# convert the response to text to obtain the html\n",
    "html = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish Chrome driver executable path. Make sure to dfine actual location on your drive.\n",
    "executable_path = {'executable_path': 'C:/Users/jaysu/chromedriver'}\n",
    "\n",
    "# Open a splinter browser\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the defined URL on your splinter browser\n",
    "browser.visit(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BeautifulSoup object with the splinter broswer.html method to parse the html with 'html.parser' or 'lmxl' formats\n",
    "soup = bs(browser.html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of stories 85\nExample of the first html element block:\n<div class=\"quiver-feed-card__image\"><a aria-label=\"Feed Card Image\" href=\"https://www.surfline.com/surf-news/watch-tom-carroll-matt-grainger-break-tow-foiling-glide-empty-outside-sydney-reef/100137\" style='background-image: url(\"https://www.surfline.com/cdn-cgi/image/w=740,q=85,f=auto,fit=contain/https://d14fqx6aetz9ka.cloudfront.net/wp-content/uploads/2020/10/13192933/TC_Surfline_foil_oct20.jpg\");' tabindex=\"0\" target=\"\"></a></div>\n"
     ]
    }
   ],
   "source": [
    "# find all the image cards that hold the links to the stories\n",
    "news_links = soup.find_all('div', class_='quiver-feed-card__image')\n",
    "\n",
    "# check to see the first element contains element contents desired\n",
    "print(f'Number of stories {len(news_links)}')\n",
    "print(f'Example of the first html element block:')\n",
    "print(news_links[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scraped news article: Russo Cam: A watery look into the North Shoreâ€™s \"secret society.\"\n--------------------------------\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-864574c4d6ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mp_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ul'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sl-article-tags'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'li'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mtags_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     post = {\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "for item in news_links:\n",
    "    # title = []\n",
    "    p_text = []\n",
    "    tags_text = []\n",
    "    url = item.find('a')['href']\n",
    "    browser.visit(url)\n",
    "    time.sleep(1)\n",
    "    soup = bs(browser.html, 'html.parser')\n",
    "    title = soup.find('h1').text # title of article\n",
    "    p_copy = soup.find_all('p')\n",
    "    for copy in p_copy:\n",
    "        p_text.append(copy.text)\n",
    "    tags = soup.find('ul', class_='sl-article-tags')\n",
    "    for tag in tags.find_all('li'):\n",
    "        tags_text.append(tag.text)\n",
    "    post = {\n",
    "        'title': title,\n",
    "        'p_text': p_text,\n",
    "        'tags_text': tags_text,\n",
    "    }\n",
    "    print(f'Scraped news article: {title}')\n",
    "    print('--------------------------------')\n",
    "    # collection.insert_one(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_text = []\n",
    "tags = soup.find('ul', class_='sl-article-tags')\n",
    "# for tag in tags.find_all('li'):\n",
    "#     tags_text.append(tag.text)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = soup.find('ul', class_='sl-article-tags')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_text = []\n",
    "# p_copy = soup.find_all('p')\n",
    "# for copy in p_copy:\n",
    "#     p_text.append(copy.text)\n",
    "\n",
    "# p_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_copy.text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}